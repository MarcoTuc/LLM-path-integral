{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 36 key-value pairs and 197 tensors from ./models/Phi-3.5-mini-instruct.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Phi 3.5 Mini Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Phi-3.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = mini\n",
      "llama_model_loader: - kv   6:                            general.license str              = mit\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/microsoft/Phi-...\n",
      "llama_model_loader: - kv   8:                               general.tags arr[str,3]       = [\"nlp\", \"code\", \"text-generation\"]\n",
      "llama_model_loader: - kv   9:                          general.languages arr[str,1]       = [\"multilingual\"]\n",
      "llama_model_loader: - kv  10:                        phi3.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  13:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  14:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv  15:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  16:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  17:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  18:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  19:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  21:              phi3.attention.sliding_window u32              = 262144\n",
      "llama_model_loader: - kv  22:              phi3.rope.scaling.attn_factor f32              = 1.190238\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  27:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  30:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
      "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   67 tensors\n",
      "llama_model_loader: - type q8_0:  130 tensors\n",
      "llm_load_vocab: special tokens cache size = 14\n",
      "llm_load_vocab: token to piece cache size = 0.1685 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_swa            = 262144\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 3.78 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Phi 3.5 Mini Instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 2070 with Max-Q Design, compute capability 7.5, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.21 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    99.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3772.59 MiB\n",
      ".....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   192.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  192.00 MiB, K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    83.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     7.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'user' %}{{'<|user|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\\n' + message['content'] + '<|end|>\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\\n' }}{% else %}{{ eos_token }}{% endif %}\", 'phi3.rope.scaling.original_context_length': '4096', 'general.architecture': 'phi3', 'phi3.rope.scaling.attn_factor': '1.190238', 'general.license': 'mit', 'phi3.context_length': '131072', 'general.type': 'model', 'general.license.link': 'https://huggingface.co/microsoft/Phi-3.5-mini-instruct/resolve/main/LICENSE', 'tokenizer.ggml.pre': 'default', 'general.basename': 'Phi-3.5', 'tokenizer.ggml.padding_token_id': '32000', 'phi3.attention.head_count': '32', 'phi3.attention.head_count_kv': '32', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.embedding_length': '3072', 'phi3.rope.dimension_count': '96', 'general.finetune': 'instruct', 'general.file_type': '7', 'phi3.rope.freq_base': '10000.000000', 'phi3.attention.sliding_window': '262144', 'phi3.block_count': '32', 'tokenizer.ggml.model': 'llama', 'phi3.feed_forward_length': '8192', 'general.name': 'Phi 3.5 Mini Instruct', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.size_label': 'mini', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.add_eos_token': 'false'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
      "' }}{% else %}{{ eos_token }}{% endif %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import llama_cpp\n",
    "\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Italy\"\n",
    "k = 4\n",
    "max_depth = 5\n",
    "cProfile.run(\"G = phrase_graph(phrase, k, max_depth)\", \"stats\")\n",
    "# G = phrase_graph(phrase, k, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 29 17:11:57 2024    stats\n",
      "\n",
      "         35851 function calls (35843 primitive calls) in 14.088 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      341    5.536    0.016    5.536    0.016 {built-in method torch.tensor}\n",
      "      341    5.468    0.016    5.468    0.016 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:368(get_logits)\n",
      "      341    1.163    0.003    1.163    0.003 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:354(decode)\n",
      "      341    0.857    0.003    0.857    0.003 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "      341    0.741    0.002   14.003    0.041 /home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py:18(get_next_k_tokens)\n",
      "      341    0.064    0.000    6.713    0.020 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:625(eval)\n",
      "      341    0.063    0.000    0.063    0.000 {built-in method torch.topk}\n",
      "     1364    0.035    0.000    0.037    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:217(detokenize)\n",
      "      341    0.029    0.000    0.029    0.000 {method 'softmax' of 'torch._C.TensorBase' objects}\n",
      "      341    0.024    0.000    0.025    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:192(tokenize)\n",
      "        3    0.017    0.006    0.017    0.006 {method 'poll' of 'select.epoll' objects}\n",
      "        3    0.011    0.004   10.024    3.341 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:1908(_run_once)\n",
      "      341    0.007    0.000    0.864    0.003 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:567(eval_logits)\n",
      "        2    0.007    0.003    0.007    0.003 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "      341    0.006    0.000    0.006    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "      341    0.005    0.000    0.005    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/ctypeslib.py:351(_ctype_ndarray)\n",
      "      341    0.005    0.000    0.005    0.000 {built-in method numpy.asarray}\n",
      "     1365    0.004    0.000    0.006    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:421(add_node)\n",
      "     1364    0.004    0.000    0.006    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:648(add_edge)\n",
      "      341    0.004    0.000    0.004    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/ctypes/__init__.py:517(cast)\n",
      "      341    0.004    0.000    0.004    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:568(set_batch)\n",
      "      341    0.003    0.000    0.018    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/ctypeslib.py:506(as_array)\n",
      "      341    0.003    0.000    0.011    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/torch/_tensor.py:1037(__iter__)\n",
      "      341    0.003    0.000    0.003    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:326(kv_cache_seq_rm)\n",
      "        1    0.002    0.002    3.824    3.824 /home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py:88(phrase_graph)\n",
      "      341    0.002    0.000    0.002    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      341    0.002    0.000    0.002    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      341    0.002    0.000    0.031    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/torch/nn/functional.py:1855(softmax)\n",
      "     1364    0.001    0.000    0.038    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama_tokenizer.py:49(detokenize)\n",
      "      697    0.001    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "     1364    0.001    0.000    0.001    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:146(token_bos)\n",
      "     2730    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
      "     1364    0.001    0.000    0.039    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:590(detokenize)\n",
      "     1364    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
      "     2729    0.001    0.000    0.002    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/utils/misc.py:595(_clear_cache)\n",
      "      341    0.001    0.000    0.026    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama_tokenizer.py:44(tokenize)\n",
      "     3083    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      341    0.001    0.000    0.001    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:79(n_ctx_train)\n",
      "     2729    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "      2/1    0.001    0.000   14.085   14.085 <string>:1(<module>)\n",
      "     1368    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "      343    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "      341    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "      341    0.000    0.000    0.000    0.000 {built-in method _ctypes.POINTER}\n",
      "     1369    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      341    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "      341    0.000    0.000    0.026    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:574(tokenize)\n",
      "      341    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "      341    0.000    0.000    0.000    0.000 /home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py:118(is_utf8)\n",
      "      343    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.014    0.014 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/decorator.py:229(fun)\n",
      "      341    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:621(reset)\n",
      "      346    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "      2/1    0.000    0.000   14.085   14.085 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.014    0.014 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:833(_writeout_input_cache)\n",
      "        8    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/ipkernel.py:775(_clean_thread_parent_frames)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1533(enumerate)\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:676(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3624(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:718(_validate)\n",
      "        3    0.000    0.000    0.041    0.014 /home/marco/miniconda3/envs/epfl/lib/python3.12/selectors.py:451(select)\n",
      "        1    0.000    0.000    0.014    0.014 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:845(writeout_cache)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:316(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3119(_bind)\n",
      "       28    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1196(ident)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/iostream.py:127(_event_pipe_gc)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/tasks.py:653(sleep)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:86(_run)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/iostream.py:118(_run_event_pipe_gc)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2882(args)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1527(_notify_observers)\n",
      "        8    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:732(time)\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1220(is_alive)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:36(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:741(call_later)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3631(set)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:155(cancel)\n",
      "      9/3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/decorator.py:199(fix)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:765(call_at)\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:689(set)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'set_result' of '_asyncio.Future' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:311(_acquire_restore)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:812(_call_soon)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3254(bind)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:727(_cross_validate)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1512(_notify_trait)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3474(validate)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2935(apply_defaults)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/futures.py:311(_set_result_unless_cancelled)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:446(create_future)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:708(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:783(call_soon)\n",
      "        1    0.000    0.000    0.014    0.014 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:55(only_when_enabled)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/graph.py:59(__set__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:627(clear)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:111(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:302(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:2304(validate)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1523(notify_change)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1153(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:299(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:839(_writeout_output_cache)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:37(__set__)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _heapq.heappop}\n",
      "       22    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/typing.py:2132(cast)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/selector_events.py:750(_process_events)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3486(validate_elements)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:72(cancel)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2905(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:308(_release_save)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _contextvars.copy_context}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        8    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:2003(get_debug)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _asyncio.get_running_loop}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:63(__set__)\n",
      "       10    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2794(kind)\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:601(is_set)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _heapq.heappush}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'cancelled' of '_asyncio.Future' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:538(_check_closed)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:314(_is_owned)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3075(parameters)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:1903(_timer_handle_cancelled)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2782(name)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2874(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x76b0541f6480>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "p = pstats.Stats(\"stats\")\n",
    "p.sort_stats(SortKey.TIME)\n",
    "p.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
