{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 36 key-value pairs and 197 tensors from ./models/Phi-3.5-mini-instruct.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Phi 3.5 Mini Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Phi-3.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = mini\n",
      "llama_model_loader: - kv   6:                            general.license str              = mit\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/microsoft/Phi-...\n",
      "llama_model_loader: - kv   8:                               general.tags arr[str,3]       = [\"nlp\", \"code\", \"text-generation\"]\n",
      "llama_model_loader: - kv   9:                          general.languages arr[str,1]       = [\"multilingual\"]\n",
      "llama_model_loader: - kv  10:                        phi3.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  13:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  14:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv  15:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  16:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  17:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  18:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  19:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  21:              phi3.attention.sliding_window u32              = 262144\n",
      "llama_model_loader: - kv  22:              phi3.rope.scaling.attn_factor f32              = 1.190238\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  27:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  30:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
      "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   67 tensors\n",
      "llama_model_loader: - type q8_0:  130 tensors\n",
      "llm_load_vocab: special tokens cache size = 14\n",
      "llm_load_vocab: token to piece cache size = 0.1685 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_swa            = 262144\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 3.78 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Phi 3.5 Mini Instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 2070 with Max-Q Design, compute capability 7.5, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.21 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    99.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3772.59 MiB\n",
      ".....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   192.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  192.00 MiB, K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    83.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     7.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 2\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'user' %}{{'<|user|>\\n' + message['content'] + '<|end|>\\n'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\\n' + message['content'] + '<|end|>\\n'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\\n' }}{% else %}{{ eos_token }}{% endif %}\", 'phi3.rope.scaling.original_context_length': '4096', 'general.architecture': 'phi3', 'phi3.rope.scaling.attn_factor': '1.190238', 'general.license': 'mit', 'phi3.context_length': '131072', 'general.type': 'model', 'general.license.link': 'https://huggingface.co/microsoft/Phi-3.5-mini-instruct/resolve/main/LICENSE', 'tokenizer.ggml.pre': 'default', 'general.basename': 'Phi-3.5', 'tokenizer.ggml.padding_token_id': '32000', 'phi3.attention.head_count': '32', 'phi3.attention.head_count_kv': '32', 'phi3.attention.layer_norm_rms_epsilon': '0.000010', 'phi3.embedding_length': '3072', 'phi3.rope.dimension_count': '96', 'general.finetune': 'instruct', 'general.file_type': '7', 'phi3.rope.freq_base': '10000.000000', 'phi3.attention.sliding_window': '262144', 'phi3.block_count': '32', 'tokenizer.ggml.model': 'llama', 'phi3.feed_forward_length': '8192', 'general.name': 'Phi 3.5 Mini Instruct', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.size_label': 'mini', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.add_eos_token': 'false'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {% for message in messages %}{% if message['role'] == 'system' and message['content'] %}{{'<|system|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
      "' + message['content'] + '<|end|>\n",
      "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
      "' }}{% else %}{{ eos_token }}{% endif %}\n",
      "Using chat eos_token: <|endoftext|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import llama_cpp\n",
    "\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 36 key-value pairs and 197 tensors from ./models/Phi-3.5-mini-instruct.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = phi3\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Phi 3.5 Mini Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Phi-3.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = mini\n",
      "llama_model_loader: - kv   6:                            general.license str              = mit\n",
      "llama_model_loader: - kv   7:                       general.license.link str              = https://huggingface.co/microsoft/Phi-...\n",
      "llama_model_loader: - kv   8:                               general.tags arr[str,3]       = [\"nlp\", \"code\", \"text-generation\"]\n",
      "llama_model_loader: - kv   9:                          general.languages arr[str,1]       = [\"multilingual\"]\n",
      "llama_model_loader: - kv  10:                        phi3.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:  phi3.rope.scaling.original_context_length u32              = 4096\n",
      "llama_model_loader: - kv  12:                      phi3.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  13:                   phi3.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  14:                           phi3.block_count u32              = 32\n",
      "llama_model_loader: - kv  15:                  phi3.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  16:               phi3.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv  17:      phi3.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  18:                  phi3.rope.dimension_count u32              = 96\n",
      "llama_model_loader: - kv  19:                        phi3.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  20:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  21:              phi3.attention.sliding_window u32              = 262144\n",
      "llama_model_loader: - kv  22:              phi3.rope.scaling.attn_factor f32              = 1.190238\n",
      "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  27:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  30:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  31:            tokenizer.ggml.padding_token_id u32              = 32000\n",
      "llama_model_loader: - kv  32:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  33:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
      "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   67 tensors\n",
      "llama_model_loader: - type q8_0:  130 tensors\n",
      "llm_load_vocab: special tokens cache size = 14\n",
      "llm_load_vocab: token to piece cache size = 0.1685 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = phi3\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32064\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 96\n",
      "llm_load_print_meta: n_swa            = 262144\n",
      "llm_load_print_meta: n_embd_head_k    = 96\n",
      "llm_load_print_meta: n_embd_head_v    = 96\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 3072\n",
      "llm_load_print_meta: n_embd_v_gqa     = 3072\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 3.82 B\n",
      "llm_load_print_meta: model size       = 3.78 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = Phi 3.5 Mini Instruct\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 32000 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32007 '<|end|>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.21 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    99.81 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  3772.59 MiB\n",
      ".....................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_backend_cuda_buffer_type_alloc_buffer: allocating 192.00 MiB on device 0: cudaMalloc failed: out of memory\n",
      "llama_kv_cache_init: failed to allocate buffer for kv cache\n",
      "llama_new_context_with_model: llama_kv_cache_init() failed for self-attention cache\n",
      "[autoreload of path failed: Traceback (most recent call last):\n",
      "  File \"/home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/home/marco/miniconda3/envs/epfl/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py\", line 9, in <module>\n",
      "    model = llama_cpp.Llama(\n",
      "            ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py\", line 391, in __init__\n",
      "    _LlamaContext(\n",
      "  File \"/home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py\", line 298, in __init__\n",
      "    raise ValueError(\"Failed to create llama_context\")\n",
      "ValueError: Failed to create llama_context\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Italy\"\n",
    "k = 4\n",
    "max_depth = 5\n",
    "G = phrase_graph(phrase, k, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 29 17:25:27 2024    stats\n",
      "\n",
      "         35156 function calls (35145 primitive calls) in 13.641 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      341    5.403    0.016    5.403    0.016 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:368(get_logits)\n",
      "      341    5.257    0.015    5.258    0.015 {built-in method torch.tensor}\n",
      "      341    1.165    0.003    1.165    0.003 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:354(decode)\n",
      "      341    0.813    0.002    0.813    0.002 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "      341    0.676    0.002   13.550    0.040 /home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py:16(get_next_k_tokens)\n",
      "      341    0.072    0.000    0.072    0.000 {built-in method torch.topk}\n",
      "      341    0.066    0.000    6.662    0.020 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:625(eval)\n",
      "      2/1    0.042    0.021   13.619   13.619 <string>:1(<module>)\n",
      "     1364    0.036    0.000    0.037    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:217(detokenize)\n",
      "      341    0.027    0.000    0.028    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:192(tokenize)\n",
      "        2    0.009    0.004    0.009    0.004 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "      341    0.007    0.000    0.820    0.002 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:567(eval_logits)\n",
      "      341    0.006    0.000    0.006    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "      341    0.005    0.000    0.005    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/ctypeslib.py:351(_ctype_ndarray)\n",
      "        1    0.005    0.005    9.082    9.082 /home/marco/Desktop/Coding/Varcode/EPFL/LLM-path-integral/path.py:77(phrase_graph)\n",
      "      341    0.004    0.000    0.004    0.000 {built-in method numpy.asarray}\n",
      "     1365    0.004    0.000    0.007    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:421(add_node)\n",
      "     1364    0.004    0.000    0.006    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:648(add_edge)\n",
      "      341    0.004    0.000    0.004    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/ctypes/__init__.py:517(cast)\n",
      "      341    0.004    0.000    0.004    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:568(set_batch)\n",
      "      341    0.003    0.000    0.019    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/ctypeslib.py:506(as_array)\n",
      "      341    0.003    0.000    0.012    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/torch/_tensor.py:1037(__iter__)\n",
      "      341    0.003    0.000    0.003    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:326(kv_cache_seq_rm)\n",
      "      341    0.002    0.000    0.002    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      341    0.002    0.000    0.002    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      713    0.002    0.000    0.002    0.000 {built-in method builtins.isinstance}\n",
      "     1364    0.001    0.000    0.039    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama_tokenizer.py:49(detokenize)\n",
      "     1364    0.001    0.000    0.001    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:146(token_bos)\n",
      "     1364    0.001    0.000    0.040    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:590(detokenize)\n",
      "     2730    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
      "     1364    0.001    0.000    0.001    0.000 {method 'decode' of 'bytes' objects}\n",
      "     2729    0.001    0.000    0.002    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/utils/misc.py:595(_clear_cache)\n",
      "     3091    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      341    0.001    0.000    0.029    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama_tokenizer.py:44(tokenize)\n",
      "      341    0.001    0.000    0.001    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/_internals.py:79(n_ctx_train)\n",
      "     2982    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "      341    0.001    0.000    0.001    0.000 {built-in method _ctypes.POINTER}\n",
      "      341    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "     1374    0.001    0.000    0.001    0.000 {method 'get' of 'dict' objects}\n",
      "      342    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "     1367    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "      341    0.000    0.000    0.029    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:574(tokenize)\n",
      "      341    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "      343    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.009    0.009 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/decorator.py:229(fun)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "      341    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/llama_cpp/llama.py:621(reset)\n",
      "      344    0.000    0.000    0.000    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "       16    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/ipkernel.py:775(_clean_thread_parent_frames)\n",
      "        8    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1533(enumerate)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      4/1    0.000    0.000   13.619   13.619 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/_core/_multiarray_umath.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1062(get_code)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
      "       56    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1196(ident)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _io.open_code}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1183(get_data)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/tasks.py:653(sleep)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.listdir}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1590(find_spec)\n",
      "        1    0.000    0.000    0.009    0.009 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:845(writeout_cache)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1240(_find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:316(__init__)\n",
      "        1    0.000    0.000    0.009    0.009 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:833(_writeout_input_cache)\n",
      "      2/1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:1304(_find_and_load_unlocked)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/iostream.py:127(_event_pipe_gc)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3119(_bind)\n",
      "      2/1    0.000    0.000    0.001    0.001 <frozen importlib._bootstrap>:1349(_find_and_load)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:304(acquire)\n",
      "       13    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:126(_path_join)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:482(cache_from_source)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:426(_get_module_lock)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:718(_validate)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/ipykernel/iostream.py:118(_run_event_pipe_gc)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1527(_notify_observers)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3631(set)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:86(_run)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2935(apply_defaults)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:732(time)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1453(_path_hooks)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
      "        2    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:911(_load_unlocked)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:733(_init_module_attrs)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:802(spec_from_file_location)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'run' of '_contextvars.Context' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:676(__get__)\n",
      "        3    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1220(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1488(_get_spec)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/decorator.py:199(fix)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:155(cancel)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:689(set)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:132(_path_split)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3474(validate)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:741(call_later)\n",
      "       12    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:989(exec_module)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:806(module_from_spec)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:124(setdefault)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:74(__new__)\n",
      "        6    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:629(get)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:751(_compile_bytecode)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:1908(_run_once)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:611(_get_cached)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1585(_get_spec)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:372(release)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__dir__' of 'module' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/futures.py:311(_set_result_unless_cancelled)\n",
      "      6/3    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:727(_cross_validate)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3624(validate_elements)\n",
      "       11    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:36(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3254(bind)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:765(call_at)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1512(_notify_trait)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:150(_path_is_mode_type)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_unpack_uint32)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1466(_path_importer_cache)\n",
      "       30    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/selectors.py:451(select)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:708(__set__)\n",
      "      5/3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:480(_call_with_frames_removed)\n",
      "        1    0.000    0.000    0.009    0.009 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:55(only_when_enabled)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1641(_fill_cache)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1564(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:311(_acquire_restore)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:666(_classify_pyc)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:812(_call_soon)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'poll' of 'select.epoll' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen zipimport>:64(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:982(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2882(args)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1682(path_hook_for_FileFinder)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:232(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:446(create_future)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:2304(validate)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'set_result' of '_asyncio.Future' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:162(__enter__)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:1523(notify_change)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:134(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:159(_path_isfile)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1517(find_spec)\n",
      "        5    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:699(_validate_timestamp_pyc)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:783(call_soon)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:643(_check_name_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:48(_new_module)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:491(_verbose_message)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/IPython/core/history.py:839(_writeout_output_cache)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:302(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:1153(_wait_for_tstate_lock)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:72(cancel)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:632(cached)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:82(remove)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:79(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/graph.py:59(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:299(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:445(cb)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:420(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__import__}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1202(path_stats)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/_distutils_hack/__init__.py:89(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heappop}\n",
      "       22    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/typing.py:2132(cast)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1226(__exit__)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1222(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:627(clear)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/events.py:111(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1570(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _imp.find_frozen}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:308(_release_save)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2905(kwargs)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:37(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/traitlets/traitlets.py:3486(validate_elements)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:185(_path_abspath)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1128(find_spec)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/selector_events.py:750(_process_events)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:180(_path_isabs)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "       10    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2794(kind)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x65387b782300}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:1903(_timer_handle_cancelled)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:164(_path_isdir)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _contextvars.copy_context}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:599(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _asyncio.get_running_loop}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1153(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:645(parent)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:2003(get_debug)\n",
      "        2    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/asyncio/base_events.py:538(_check_closed)\n",
      "        3    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:601(is_set)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:412(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2782(name)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/threading.py:314(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:3075(parameters)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'cancelled' of '_asyncio.Future' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heappush}\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/networkx/classes/digraph.py:63(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:71(_relax_case)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:986(create_module)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/inspect.py:2874(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 /home/marco/miniconda3/envs/epfl/lib/python3.12/site-packages/numpy/_core/__init__.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:158(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:653(has_location)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1178(get_filename)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7470f309dcd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from pstats import SortKey\n",
    "\n",
    "cProfile.run(\"G = phrase_graph(phrase, k, max_depth)\", \"stats\")\n",
    "p = pstats.Stats(\"stats\")\n",
    "p.sort_stats(SortKey.TIME)\n",
    "p.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
